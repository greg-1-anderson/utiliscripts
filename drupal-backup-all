#!/bin/bash
#
# Usage:
#
#    drupal-backup-all site1 site2 site3
#
# Alternate example - backup each site daily at 3am from cron:
#
#    0  3  *  *  *  /usr/bin/env PATH=/usr/local/bin:/usr/bin:/bin drupal-backup-all site1 site2 site3
#
# Configuration:
#
# Each site named in the commandline arguments must have a Drush site alias
# file named, for example, site1.aliases.drushrc.php, and it must have alias
# records named live, backup and update.  The live site is usually remote,
# while the backup and update sites must be local.
#
# Example alias file site1.aliases.drushrc.php:
#
# $aliases['live'] = array (
#   'remote-host' => 'vps.myisp.com',
#   'remote-user' => 'www-admin',
#   'uri' => 'http://site1.org',
#   'root' => '/srv/www/site1.org/htdocs',
# );
#
# $aliases['backup'] = array (
#   'root' => '/srv/www/backup.site1.org/htdocs',
#   'uri' => 'http://site1.org',
#   'target-command-specific' => array (
#     'sql-sync' => array (
#       'enable' => array ('environment_indicator'),
#       'permission' => array (
#         'authenticated user' => array (
#           'add' => array('access environment indicator'),
#         ),
#         'anonymous user' => array (
#           'add' => 'access environment indicator',
#         ),
#       ),
#     ),
#   ),
# );
#
# $aliases['update'] = array (
#   'root' => '/srv/www/backup.site1.org/htdocs',
#   'uri' => 'http://site1.org',
#   'target-command-specific' => array (
#     'sql-sync' => array (
#       'enable' => array ('stage_file_proxy'),
#     ),
#   ),
# );
#
# You must manually set up the 'backup' and 'update' sites; this script
# will not create them for you.  The sql-sync enable configuration shown
# above is an example; for this site, environment indicator is enabled on
# the backup site, and stage_file_proxy is enabled on the update site. You
# do not need to enable these modules, and you may wish to enable others.
# If you use this feature, you must copy the sync-enable script to your
# ~/.drush folder.  For more information on sync-enable, see:
#
#   http://drupalcode.org/project/drush.git/blob/HEAD:/examples/sync_enable.drush.inc
#
# See also: http://groups.drupal.org/node/263458#comment-840478
#

FORCE=false
VERBOSE=false
QUIET='>/dev/null 2>&1'

# Start with an empty backup list.
backup_list=

#
# Parse command line args
#
while [ $# -gt 0 ] ; do

  option=$1
  shift

  case "$option" in
    --force|-f)
      FORCE=true
      ;;

    --verbose|-v)
      VERBOSE=true
      QUIET=
      ;;

    -* )
      echo "Unknown option $option"
      exit 1;
      ;;

    * )
      # Test to see if we have site aliases defined for the specified site.
      # TODO: We assume 'live' is remote and 'backup' is local.  Confirm this?
      site=$option
      if [ -z "$(drush sa --short @$site.live)" ] || [ -z "$(drush sa --short @$site.backup)" ] ; then
        (
          echo "The site alias @$option is either not defined, or is missing"
          echo "'live' and/or 'backup' site records."
        ) 1>&2
        exit 1
      fi
      backup_list="$backup_list $site"
      ;;

    esac
done

if [ -z "$backup_list" ] ; then
  echo "No backup sites listed." 1>&2
  exit 1
fi

# Keep a list of sites updated
update_list=

# Loop over all of the sites, backing up each in turn.
for site in ${backup_list} ; do
  backup_dir=/data/archive/drupal/$site
  mkdir -p "$backup_dir"
  hash_file=$backup_dir/${site}.hash
  cur_hash_file=$backup_dir/${site}-cur.hash
  diff_file=$backup_dir/${site}.hash
  dump_file=$backup_dir/${site}.sql
  update_list_file=$backup_dir/${site}.updates
  cur_update_list_file=$backup_dir/${site}-cur.updates
  update_log_file=$backup_dir/${site}-updatelog
  msg="=== Checking ${site} for changes ==="
  $FORCE && msg="=== Backup forced for ${site} ==="
  echo $msg 1>&2
  drush @$site.live sql-hash --tables-list='users,permission,node' --strict=0 > $cur_hash_file 2>/dev/null
  if [ ! -f $hash_file ] || [ "x`diff $cur_hash_file $hash_file`" != "x" ] || $FORCE ; then
    echo "Begin backup of $site" 1>&2

    # Show which tables changed since last time.
    diff -U 0 $hash_file $cur_hash_file > $diff_file
    mv -f $cur_hash_file $hash_file

    # First, insure that the git repository is clean on the live site.
    # We expect that changes to code should not be made on the live site,
    # but if there are any dirty files in the git repository, we will
    # autocommit them.
    live_root=$(drush sa @$site.live --component=root)
    drush @$site.live ssh "cd $live_root && git add -A && git commit -m 'Automatic commit by drupal-backup-all script' && git push" 1>&2
    # Next, make sure backup site has the most recent code.
    (
      cd $(drush drupal-directory @$site.backup)
      git pull 1>&2
    )
    # Get current commit tag and write it into live database
    head_commithash=$(drush @$site.live ssh 'git rev-parse HEAD')
    drush -v @$site.live vset --always-set -y git-commithash "$head_commithash"

    # Sync the sql database from the live site to the backup site,
    # Drop the database into place in the backup folder by using it
    # as the target-dump.
    drush -y sql-sync --target-dump="$dump_file" @$site.live @$site.backup $QUIET
    drush -y @$site.backup cc all 1>&2

    # Check to see if %files has been committed to the git repository.
    # If it has not, then the log line will be empty.
    files_dir=$(drush dd @$site.backup:%files)
    log_line=$(cd $(drush dd @$site.backup:%files); git log -1 --oneline $files_dir)
    # If %files are not in the repository, then copy them via rsync
    if [ -z "$log_line" ] ; then
      drush -y rsync @$site.live:%files @$site.backup:%files $QUIET
    fi

    # Do the same operation with %private
    private_dir=$(drush dd @$site.backup:%private 2>/dev/null)
    if [ -n "$private_dir" ] ; then
      log_line=$(cd $(drush dd @$site.backup:%private); git log -1 --oneline $private_dir)
      # If %private are not in the repository, then copy them via rsync
      if [ -z "$log_line" ] ; then
        drush -y rsync @$site.live:%private @$site.backup:%private $QUIET
      fi
    fi

    # TODO: What about rolling backups?  Should we use migratehistories, or
    # just try committing the sql dump file to a get repository?

    echo "Backup complete for $site" 1>&2
  else
    echo "Backup not needed for $site" 1>&2
    rm -f $cur_hash_file
  fi

  # Check to see if any updates are available.
  echo "=== Checking ${site} for updates ===" 1>&2
  drush @$site.backup pm-updatecode -n --pipe > $cur_update_list_file 2>/dev/null
  if [ -s $cur_update_list_file ] ; then
    if [ ! -f $update_list_file ] || [ "x`diff $cur_update_list_file $update_list_file`" != "x" ] ; then
      update_list="${update_list} $site"
      # If there is a @site.update alias defined, then automatically
      # perform a pm-update, so the result will be available for testing.
      if [ -n "$(drush sa --short @$site.update)" ] ; then
        # TODO: If we preserved the creation date of $update_list_file,
        # then we could output how long this site has been waiting for an
        # update below.
        mv -f $cur_update_list_file $update_list_file
        echo "Begin update of $site" 1>&2

        # Make sure update site has the most recent code.
        (
          cd $(drush drupal-directory @$site.update)
          git pull 1>&2
        )
        # Sync the database
        drush -y sql-sync --source-dump="$dump_file" @$site.backup @$site.update $QUIET
        drush -y @$site.update cc all 1>&2

        # Again, copy %files and %private for convenience
        files_dir=$(drush dd @$site.update:%files)
        log_line=$(cd $(drush dd @$site.update:%files); git log -1 --oneline $files_dir)
        if [ -z "$log_line" ] ; then
          drush -y rsync @$site.backup:%files @$site.update:%files $QUIET
        fi
        private_dir=$(drush dd @$site.update:%private 2>/dev/null)
        if [ -n "$private_dir" ] ; then
          log_line=$(cd $(drush dd @$site.update:%private); git log -1 --oneline $private_dir)
          # If %private are not in the repository, then copy them via rsync
          if [ -z "$log_line" ] ; then
            drush -y rsync @$site.backup:%private @$site.update:%private $QUIET
          fi
        fi

        # Run the update
        drush -y @$site.update pm-update > $update_log_file 2>&1
        echo "Update complete for $site" 1>&2
      else
        echo "Update needed for $site; please make an .update site alias" 1>&2
        # Add content to the update list so that it will be different, and
        # we will try again next time.
        date >> $update_list_file
      fi
    else
      echo "No update needed for $site; successfully updated last backup" 1>&2
      rm -f $cur_update_list_file
    fi
  else
    echo "No update needed for $site; live site is up-to-date" 1>&2
    rm -f $cur_update_list_file
    rm -f $update_list_file
    rm -f $update_log_file
  fi
done
